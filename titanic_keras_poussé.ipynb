{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas pour manipuler les tableaux de données\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# scikit learn pour les outils de machine learning\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "# librairies pour la visualisation de données\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# et quelques options visuelles\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "sns.set(rc={'figure.figsize':(15,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>LastNameNum</th>\n",
       "      <th>TicketSibling</th>\n",
       "      <th>isParent</th>\n",
       "      <th>isEnfant</th>\n",
       "      <th>AgeBin</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Servant</th>\n",
       "      <th>parentSurvived</th>\n",
       "      <th>childrenSurvived</th>\n",
       "      <th>parentDied</th>\n",
       "      <th>childrenDied</th>\n",
       "      <th>SiblingDied</th>\n",
       "      <th>SiblingSurvived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.578506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>719</td>\n",
       "      <td>-0.999433</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.623779</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>815</td>\n",
       "      <td>1.393960</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>182</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId  Survived  Pclass  Sex       Age  SibSp  Parch  Ticket  \\\n",
       "train            1       0.0       3    1 -0.578506      1      0     719   \n",
       "train            2       1.0       1    0  0.623779      1      0     815   \n",
       "\n",
       "           Fare  Embarked  Title  LastNameNum  TicketSibling  isParent  \\\n",
       "train -0.999433         2      4          100              1       0.0   \n",
       "train  1.393960         0      5          182              2       0.0   \n",
       "\n",
       "       isEnfant  AgeBin  FareBin  IsAlone  FamilySize  Servant  \\\n",
       "train       0.0       1        0        0           2        0   \n",
       "train       0.0       2        4        0           2        0   \n",
       "\n",
       "       parentSurvived  childrenSurvived  parentDied  childrenDied  \\\n",
       "train               0                 0           0             0   \n",
       "train               0                 0           0             0   \n",
       "\n",
       "       SiblingDied  SiblingSurvived  \n",
       "train            0                0  \n",
       "train            0                0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('dataForML.csv',index_col=0)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([data, pd.get_dummies(data[\"Pclass\"], prefix='_Pclass_')], axis=1)\n",
    "data=pd.concat([data, pd.get_dummies(data[\"Title\"], prefix='_Title_')], axis=1)\n",
    "data=pd.concat([data, pd.get_dummies(data[\"Embarked\"], prefix='_Embarked_')], axis=1)\n",
    "data=pd.concat([data, pd.get_dummies(data[\"Ticket\"], prefix='_Ticket_')], axis=1)\n",
    "data=pd.concat([data, pd.get_dummies(data[\"LastNameNum\"], prefix='_LastNameNum_')], axis=1)\n",
    "data = data.drop(['AgeBin','FareBin','Title','Embarked','LastNameNum','Ticket'],axis=1)\n",
    "\n",
    "y = data.loc['train','Survived'].astype('int')\n",
    "X = data.loc['train'].drop(['Survived','PassengerId'],axis=1)\n",
    "X_cible =  data.loc['test'].drop(['Survived','PassengerId'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "tree=ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "       max_depth=22, max_features='auto', max_leaf_nodes=None,\n",
    "       min_impurity_decrease=0.0003,\n",
    "       min_samples_leaf=1, min_samples_split=2,\n",
    "       min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
    "       oob_score=False, random_state=42, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# après quelques tests je me limite à supprimer 'isEnfant'\n",
    "X=X.drop(['isEnfant'], axis=1)\n",
    "X_cible=X_cible.drop(['isEnfant'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'nb_epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdadelta\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# exécution du modèle\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnb_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\moon\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\moon\\anaconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'nb_epoch'"
     ]
    }
   ],
   "source": [
    "# Modules KERAS\n",
    "import keras\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "\n",
    "# définition de n_cols : la dimension des données d'entrée\n",
    "n_cols = X.shape[1]\n",
    "\n",
    "# définition du seed (graine des fonctions d'aléas) afin de pouvoir reproduire à l'identique les résultats des calculs\n",
    "seed(42)\n",
    "# Définition de la graine aléatoire pour TensorFlow\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "# Architecture du modèle, un ecouche d'entrée, une de sortie et deux couches \"profondes\"\n",
    "# cette architecture est un peu empirique, il n'y a pas vraiment de rêgles permettant de définir\n",
    "# la meilleur architecture\n",
    "nb_neurones=47\n",
    "model = Sequential()\n",
    "model.add(Dense(nb_neurones, activation='linear', input_shape = (n_cols,)))\n",
    "model.add(Dense(nb_neurones, activation='linear')) \n",
    "model.add(Dense(nb_neurones, activation='linear')) \n",
    "\n",
    "# option dropout, cette option évite le surajustement (overfitting) en injectant des aléas sur les données\n",
    "# d'entrée (une partie des données est aléatoirement fixée à zero)\n",
    "model.add(Dropout(0.1))\n",
    "    \n",
    "# couche de sortie\n",
    "model.add(Dense(1, activation='sigmoid'))  # output layer\n",
    "\n",
    "# compilation du modèle\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
    "\n",
    "# exécution du modèle\n",
    "history = model.fit(X,y,epochs=200,batch_size=512, validation_split=0.2, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
